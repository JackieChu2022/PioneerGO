{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3702c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "%matplotlib inline\n",
    "\n",
    "from pandas_datareader.data import DataReader\n",
    "import yfinance as yf\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from urllib.request import urlopen, Request \n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import nltk\n",
    "nltk.downloader.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8278e38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#US market data download\n",
    "GSPC = DataReader('^GSPC', data_source = 'yahoo', start='2020-01-01', end=datetime.now())\n",
    "GSPC['SMA10'] = GSPC['Close'].rolling(10).mean()\n",
    "GSPC['type']='index'\n",
    "GSPC['ticker']=\"GSPC\"\n",
    "AAPL = DataReader('AAPL', data_source = 'yahoo', start='2020-01-01', end=datetime.now())\n",
    "AAPL['SMA10'] = AAPL['Close'].rolling(10).mean()\n",
    "AAPL['type']=\"stock\"\n",
    "AAPL['ticker']=\"AAPL\"\n",
    "AMZN = DataReader('AMZN', data_source = 'yahoo', start='2020-01-01', end=datetime.now())\n",
    "AMZN['SMA10'] = AMZN['Close'].rolling(10).mean()\n",
    "AMZN['type']=\"stock\"\n",
    "AMZN['ticker']=\"AMZN\"\n",
    "BABA = DataReader('BABA', data_source = 'yahoo', start='2020-01-01', end=datetime.now())\n",
    "BABA['SMA10'] = BABA['Close'].rolling(10).mean()\n",
    "BABA['type']=\"stock\"\n",
    "BABA['ticker']=\"BABA\"\n",
    "GOOG = DataReader('GOOG', data_source = 'yahoo', start='2020-01-01', end=datetime.now())\n",
    "GOOG['SMA10'] = GOOG['Close'].rolling(10).mean()\n",
    "GOOG['type']=\"stock\"\n",
    "GOOG['ticker']=\"GOOG\"\n",
    "TSLA = DataReader('TSLA', data_source = 'yahoo', start='2020-01-01', end=datetime.now())\n",
    "TSLA['SMA10'] = TSLA['Close'].rolling(10).mean()\n",
    "TSLA['type']=\"stock\"\n",
    "TSLA['ticker']=\"TSLA\"\n",
    "\n",
    "US=pd.concat([GSPC, AAPL, AMZN, BABA, GOOG, TSLA])\n",
    "US['region']='US'\n",
    "US['latitude']=40.730610\n",
    "US['longitude']=-73.935242\n",
    "\n",
    "#HK market data download\n",
    "HSI = DataReader('^HSI', data_source = 'yahoo', start='2020-01-01', end=datetime.now())\n",
    "HSI['SMA10'] = HSI['Close'].rolling(10).mean()\n",
    "HSI['type']=\"index\"\n",
    "HSI['ticker']=\"HSI\"\n",
    "HK0700 = DataReader('0700.HK', data_source = 'yahoo', start='2020-01-01', end=datetime.now())\n",
    "HK0700['SMA10'] = HK0700['Close'].rolling(10).mean()\n",
    "HK0700['type']=\"stock\"\n",
    "HK0700['ticker']=\"HK0700\"\n",
    "HK3690 = DataReader('3690.HK', data_source = 'yahoo', start='2020-01-01', end=datetime.now())\n",
    "HK3690['SMA10'] = HK3690['Close'].rolling(10).mean()\n",
    "HK3690['type']=\"stock\"\n",
    "HK3690['ticker']=\"HK3690\"\n",
    "HK9988 = DataReader('9988.HK', data_source = 'yahoo', start='2020-01-01', end=datetime.now())\n",
    "HK9988['SMA10'] = HK9988['Close'].rolling(10).mean()\n",
    "HK9988['type']=\"stock\"\n",
    "HK9988['ticker']=\"HK9988\"\n",
    "\n",
    "HK=pd.concat([HSI, HK0700, HK3690, HK9988])\n",
    "HK['region']=\"HK\"\n",
    "HK['latitude']=22.302711 \n",
    "HK['longitude']=114.177216\n",
    "\n",
    "#Other market data download\n",
    "JP225 = DataReader('^N225', data_source = 'yahoo', start='2020-01-01', end=datetime.now())\n",
    "JP225['SMA10'] = JP225['Close'].rolling(10).mean()\n",
    "JP225['type']=\"index\"\n",
    "JP225['ticker']=\"JP225\" \n",
    "JP225['region']=\"JP\"\n",
    "JP225['latitude']=35.652832\n",
    "JP225['longitude']=139.839478\n",
    "\n",
    "SS=DataReader('000001.SS', data_source = 'yahoo', start='2020-01-01', end=datetime.now())\n",
    "SS['SMA10'] = SS['Close'].rolling(10).mean()\n",
    "SS['type']=\"index\"\n",
    "SS['ticker']=\"SS\" \n",
    "SS['region']=\"SS\" \n",
    "SS['latitude']=31.224361 \n",
    "SS['longitude']=121.469170 \n",
    "\n",
    "raw=pd.concat([US, HK, JP225, SS])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6bea0f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.to_csv('C:/Stock_sourcedata/EDA/price.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04c49de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrap news from finwiz\n",
    "finwiz_url = 'https://finviz.com/quote.ashx?t='\n",
    "news_tables={}\n",
    "tickers =['AAPL', 'AMZN', 'BABA', 'GOOG', 'TSLA']\n",
    "for ticker in tickers:\n",
    "    url = finwiz_url + ticker\n",
    "    req = Request(url=url,headers={'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:20.0) Gecko/20100101 Firefox/20.0'}) \n",
    "    response = urlopen(req)    \n",
    "    # Read the contents of the file into 'html'\n",
    "    html = BeautifulSoup(response)\n",
    "    # Find 'news-table' in the Soup and load it into 'news_table'\n",
    "    news_table = html.find(id='news-table')\n",
    "    # Add the table to our dictionary\n",
    "    news_tables[ticker] = news_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0140edb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['AAPL',\n",
       "  'Jun-26-22',\n",
       "  '11:00AM',\n",
       "  'A cold dark place  Michael Burry thinks the market has plenty of room to plunge. But he finally sees value in these 4 stocks'],\n",
       " ['AAPL',\n",
       "  'Jun-26-22',\n",
       "  '09:28AM',\n",
       "  '2 No-Brainer Warren Buffett Stocks to Buy Now and Hold Forever'],\n",
       " ['AAPL',\n",
       "  'Jun-26-22',\n",
       "  '09:01AM',\n",
       "  'Market Plunge 2022: 3 Absolute Bargains Begging to Be Bought']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_news = []\n",
    "\n",
    "# Iterate through the news\n",
    "for file_name, news_table in news_tables.items():\n",
    "    # Iterate through all tr tags in 'news_table'\n",
    "    for x in news_table.findAll('tr'):\n",
    "        # read the text from each tr tag into text\n",
    "        # get text from a only\n",
    "        text = x.a.get_text() \n",
    "        # splite text in the td tag into a list \n",
    "        date_scrape = x.td.text.split()\n",
    "        # if the length of 'date_scrape' is 1, load 'time' as the only element\n",
    "        if len(date_scrape) == 1:\n",
    "            time = date_scrape[0]\n",
    "\n",
    "        # else load 'date' as the 1st element and 'time' as the second    \n",
    "        else:\n",
    "            date = date_scrape[0]\n",
    "            time = date_scrape[1]\n",
    "        # Extract the ticker from the file name, get the string up to the 1st '_'  \n",
    "        ticker = file_name.split('_')[0]\n",
    "\n",
    "        # Append ticker, date, time and headline as a list to the 'parsed_news' list\n",
    "        parsed_news.append([ticker, date, time,text])\n",
    "\n",
    "# print first 3 rows of news\n",
    "parsed_news[:3] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfef476b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>headline</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022-06-26</td>\n",
       "      <td>11:00AM</td>\n",
       "      <td>A cold dark place  Michael Burry thinks the ma...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022-06-26</td>\n",
       "      <td>09:28AM</td>\n",
       "      <td>2 No-Brainer Warren Buffett Stocks to Buy Now ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022-06-26</td>\n",
       "      <td>09:01AM</td>\n",
       "      <td>Market Plunge 2022: 3 Absolute Bargains Beggin...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022-06-26</td>\n",
       "      <td>08:21AM</td>\n",
       "      <td>Better Buy: Dividend Aristocrats vs. Beaten-Do...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2022-06-26</td>\n",
       "      <td>07:05AM</td>\n",
       "      <td>Have $3,000? These 2 Stocks Could Be Bargain B...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker        date     time  \\\n",
       "0   AAPL  2022-06-26  11:00AM   \n",
       "1   AAPL  2022-06-26  09:28AM   \n",
       "2   AAPL  2022-06-26  09:01AM   \n",
       "3   AAPL  2022-06-26  08:21AM   \n",
       "4   AAPL  2022-06-26  07:05AM   \n",
       "\n",
       "                                            headline  neg    neu    pos  \\\n",
       "0  A cold dark place  Michael Burry thinks the ma...  0.0  0.871  0.129   \n",
       "1  2 No-Brainer Warren Buffett Stocks to Buy Now ...  0.0  1.000  0.000   \n",
       "2  Market Plunge 2022: 3 Absolute Bargains Beggin...  0.0  1.000  0.000   \n",
       "3  Better Buy: Dividend Aristocrats vs. Beaten-Do...  0.0  0.707  0.293   \n",
       "4  Have $3,000? These 2 Stocks Could Be Bargain B...  0.0  0.859  0.141   \n",
       "\n",
       "   compound  \n",
       "0    0.4767  \n",
       "1    0.0000  \n",
       "2    0.0000  \n",
       "3    0.4404  \n",
       "4    0.2023  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the sentiment intensity analyzer\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Set column names\n",
    "columns = ['ticker', 'date', 'time', 'headline']\n",
    "\n",
    "# Convert the parsed_news list into a DataFrame called 'parsed_and_scored_news'\n",
    "parsed_and_scored_news = pd.DataFrame(parsed_news, columns=columns)\n",
    "\n",
    "# Iterate through the headlines and get the polarity scores using vader\n",
    "scores = parsed_and_scored_news['headline'].apply(vader.polarity_scores).tolist()\n",
    "\n",
    "# Convert the 'scores' list of dicts into a DataFrame\n",
    "scores_df = pd.DataFrame(scores)\n",
    "\n",
    "# Join the DataFrames of the news and the list of dicts\n",
    "parsed_and_scored_news = parsed_and_scored_news.join(scores_df, rsuffix='_right')\n",
    "\n",
    "# Convert the date column from string to datetime\n",
    "parsed_and_scored_news['date'] = pd.to_datetime(parsed_and_scored_news.date).dt.date\n",
    "\n",
    "parsed_and_scored_news.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88115b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date        ticker\n",
       "2022-06-06  BABA      0.072933\n",
       "2022-06-07  BABA      0.197350\n",
       "2022-06-08  BABA      0.173909\n",
       "2022-06-09  BABA      0.094744\n",
       "2022-06-10  BABA      0.122220\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform sentiment_score\n",
    "plt.rcParams['figure.figsize']=[10,6]\n",
    "mean_scores=parsed_and_scored_news.groupby(['ticker','date']).mean()\n",
    "mean_scores=mean_scores.unstack()\n",
    "mean_scores=mean_scores.xs('compound',axis=\"columns\").transpose()\n",
    "sentiment_score=mean_scores.stack()\n",
    "sentiment_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db0f7a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_and_scored_news.to_csv('C:/Stock_sourcedata/EDA/news.csv')\n",
    "sentiment_score.to_csv('C:/Stock_sourcedata/EDA/sentiment.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
